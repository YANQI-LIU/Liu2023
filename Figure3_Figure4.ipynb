{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd261459-ed4a-4f89-a06a-9cefc39f80e0",
   "metadata": {},
   "source": [
    "## Custom written code to generate Figure 3 and Figure 4 for Liu 2023\n",
    "\n",
    "Run under the analysis2 environment\n",
    "\n",
    "Figure 3. sum projections of group averages\n",
    "\n",
    "Figure 4. serial coronal sections\n",
    "\n",
    "Also prepares intermediate files (xlsx) for the subsequent figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5016e031-4d58-4f02-8480-c957c068c3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import warnings\n",
    "\n",
    "import tkinter.filedialog as fdialog\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a210ce9-c736-44c2-90d6-dd1b24f84fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory= r'E:\\CodeTest' \n",
    "# this directory should contain folders Horizontal_Axon, ARA_25_micron_mhd_ccf2017, and file injection_sites_results_expanded.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271c05c3-1ef5-429a-ac3f-93f56ca21620",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Figure 3\n",
    "\n",
    "Sum projections of group averages in coronal, horizontal and saggital views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613bf2ab-bf27-46a9-a796-705ea6200d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='s2'\n",
    "# change to 's1' or 's2' and repeat\n",
    "\n",
    "indir = f'{working_directory}\\\\Horizontal_Axon\\\\{region}\\\\npy'\n",
    "#specifiy input folder containing the horizontal npy files\n",
    "\n",
    "outdir =f'{working_directory}\\\\{region}_average'\n",
    "# define folder to store the results\n",
    "\n",
    "os.mkdir(outdir) \n",
    "\n",
    "in_files= os.listdir(indir)\n",
    "\n",
    "sample_files= os.listdir(indir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee4da78-50eb-4f37-a2d1-6dd0750613ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tiff(numpystack, outname):\n",
    "    \n",
    "    '''save numpy stack as tiff and sum max projection in horizontal, coronal and saggital views'''\n",
    "    \n",
    "    print('Starting to saving tif files..')\n",
    "    \n",
    "    io.imsave(outname+'_axons.tif',numpystack,check_contrast=False)\n",
    "    \n",
    "    sum_0=np.sum(numpystack, axis=0)\n",
    "    sum_1=np.sum(numpystack, axis=1)\n",
    "    sum_2=np.sum(numpystack, axis=2)\n",
    "    io.imsave(outname+ '_sum_0.tif',sum_0,check_contrast=False)\n",
    "    io.imsave(outname+ '_sum_1.tif',sum_1,check_contrast=False)\n",
    "    io.imsave(outname+ '_sum_2.tif',sum_2,check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1300f98-c7ce-46da-8dbe-0c734f67776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY FOR SAMPLES!!\n",
    "\n",
    "if region == 's1':\n",
    "    sample_dictionary= {'sim': ['AL207','AL209','AL273'],\n",
    "                        'rbp': ['AL211','AL318'],\n",
    "                        'tlx': ['AL213','AL313','AL314'],\n",
    "                        'ras': ['AL254','AL255','AL257'],\n",
    "                        'scn': ['AL290','AL291','AL292','AL293'],\n",
    "                        'nts': ['AL274','AL285','AL311']\n",
    "                       }\n",
    "elif region == 's2':\n",
    "    sample_dictionary= {'sim': ['AL281','AL286','AL321','AL322'],\n",
    "                        'rbp': ['AL288','AL326','AL327'],\n",
    "                        'tlx': ['AL278','AL280','AL319'],\n",
    "                        'ras': ['AL303','AL332','AL333'],\n",
    "                        'scn': ['AL290','AL292','AL323'],\n",
    "                        'nts': ['AL274','AL310','AL330']\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5c290c-ab60-4057-baf8-d6b23410415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on sim samples\n",
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████                                                                      | 1/6 [00:41<03:27, 41.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on rbp samples\n",
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 2/6 [01:08<02:11, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on tlx samples\n",
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:37<01:34, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ras samples\n",
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:04<00:59, 29.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on scn samples\n",
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:31<00:28, 28.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on nts samples\n",
      "Starting to saving tif files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [03:00<00:00, 30.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for genotype, sample_name in tqdm(sample_dictionary.items()):\n",
    "    \n",
    "    print ('Working on '+ genotype + ' samples') \n",
    "    \n",
    "    out_name= outdir+ f'\\\\{genotype}_average'\n",
    "    \n",
    "    relevant_npy_name= [i+'.npy' for i in sample_name]\n",
    "    # get the relevant names\n",
    "    \n",
    "    template=np.zeros([320, 528, 456])\n",
    "    # initialize np array\n",
    "    \n",
    "    for i in relevant_npy_name:\n",
    "        template+= np.load(os.path.join(indir,i))\n",
    "    \n",
    "    averaged_stack= template/ len(relevant_npy_name)\n",
    "    # average across number of involved samples\n",
    "    \n",
    "    np.save(out_name+'.npy', averaged_stack)\n",
    "    \n",
    "    averaged_stack[0,0,0]=0\n",
    "    averaged_stack[1,0,0]=0\n",
    "    # reassign these pixels back to 0\n",
    "    \n",
    "    save_tiff(averaged_stack, out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2d1d0-76b4-4d5a-991a-545acc275540",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Figure 4\n",
    "\n",
    "Serial coronal sections of group averages\n",
    "\n",
    "Sum projections of a few coronal sections centered around a given AP location\n",
    "- ie. 125 um thickness centered around AP +3 mm to -7 mm in 1 mm intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb9571b-cae0-44b6-89c1-502cb23d1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir= f'{working_directory}\\consecutive_coronal'\n",
    "os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab241f6-f160-4072-a1c6-3aad2d9daa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions=['s1', 's2']\n",
    "# define the two injection regions\n",
    "\n",
    "mouse_lines=['ras','scn','tlx','sim','rbp','nts']\n",
    "# defined the list of transgenic lines\n",
    "\n",
    "#bregma= [227.5, 0,  215]\n",
    "# bregma AP is section 215 in a coronal stack in the Allen brain 25um CCF\n",
    "\n",
    "bregma= 215\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c100c1f-f6ca-489f-aeb7-cb05fa0c10fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:15<00:00,  2.57s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through group averages\n",
    "\n",
    "for i in regions:\n",
    "    \n",
    "    \n",
    "    for j in tqdm(mouse_lines):    \n",
    "        \n",
    "        file_path= f'{working_directory}\\\\{i}_average\\\\{j}_average.npy'\n",
    "\n",
    "        axons=np.load(file_path)\n",
    "        # load horizontal npy file of group averages\n",
    "        \n",
    "        axons[0,0,0]=0\n",
    "        axons[1,0,0]=0\n",
    "        # restore these values back to 0\n",
    "        \n",
    "        coronal= axons.swapaxes(0,1)\n",
    "        # reshape axons into coronal sections\n",
    "        \n",
    "        for k in range(-3,8):\n",
    "            \n",
    "            #take -3 mm to  7 mm in 1 mm interval points with 5 sections (125 um) around this point, in terms of stereotaxic cordinate where bregma= 0\n",
    "            \n",
    "            midpoint= int( bregma + k/0.025)\n",
    "            # convert this stereotaxic point back where 1 pixel= 25 microns or 0.025 mm\n",
    "            \n",
    "            this_plane=coronal[midpoint-2 : midpoint+3,:,:].sum(0)\n",
    "            # keep 2 slices before and 2 slices after the midpoint, which is 5 slices in total= 125um thickness\n",
    "\n",
    "            out_name= f'{outdir}\\\\{i}_{j}_avg_AP{k}'\n",
    "\n",
    "            io.imsave(out_name+ '_sum.tif',this_plane,check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a4061-bcec-4e32-8b7f-c84548b4ea9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preparation categorical data as excel files for Figures 5,6 and 7\n",
    "Numbers of of axons in brain region X\n",
    "\n",
    "Should get 4 xlsx files per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea25280d-e8c9-44ff-bf75-6689aa9e19bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# useful functions\n",
    "\n",
    "def find_mousename(text):\n",
    "    #finds name of mouse that follows the typical LSENS pattern: two letters followed by 3 numbers, ie AL000\n",
    "    a= re.search('[a-zA-Z]{2}[0-9]{2,3}', text)\n",
    "    return a[0]\n",
    "\n",
    "def find_points_id_from_npy(npy_file_path):\n",
    "    \n",
    "    ''' quantify amount of axons in brain region from npy files\n",
    "    '''\n",
    "    \n",
    "    sample_array=np.load(npy_file_path)\n",
    "    \n",
    "    sample_array[0,0,0]=0\n",
    "    sample_array[1,0,0]=0\n",
    "    # reassign position 0,0,0 and 1,0,0 as 0\n",
    "    # this is because we stored number of axons (at 0,0,0) and number of cells at(1,0,0) at these locations \n",
    "\n",
    "    sample_h=np.swapaxes(sample_array, 0, 2)\n",
    "    # swap axis to match the atlas shape, this is the axon in horizontal view\n",
    "    \n",
    "    axons= np.argwhere(sample_h)\n",
    "    # find all the non-zero indices from the stack\n",
    "    \n",
    "    return sample_h, axons\n",
    "\n",
    "def get_subregion_excel(axon_points):\n",
    "    \n",
    "    ''' Quantify axon counts in the most detailed anatomical region possible\n",
    "    '''\n",
    "    \n",
    "    region_in_atlas= []\n",
    "    for i in axon_points:\n",
    "        region_in_atlas.append(int(annot_h[i[0], i[1],i[2]]))\n",
    "    #get atlas id for each non-zero indices on this side side\n",
    "\n",
    "    axon_values=[]\n",
    "    for i in axon_points:\n",
    "        axon_values.append (sample_h[i[0],i[1],i[2]])\n",
    "    # get the actual count for each non-zero indices on this side\n",
    "\n",
    "    this_data=pd.DataFrame({'id': region_in_atlas, 'counts': axon_values})\n",
    "    # store in data frame\n",
    "\n",
    "    this_data=this_data.groupby(by='id').sum()\n",
    "    # add the values from a given brain region together\n",
    "    \n",
    "    this_df=pd.merge(atlas_labels, this_data, on='id')\n",
    "    # add in additional information from allen labels and save\n",
    "    \n",
    "    return this_df\n",
    "\n",
    "def parent_df(df):\n",
    "    ''' \n",
    "    Used under the get_parent_excel function\n",
    "    group dataframe by parent id structure'''\n",
    "    \n",
    "    grouped_pd=df.groupby(['parent_structure_id'],as_index=False).sum()\n",
    "    d= {'id': grouped_pd.parent_structure_id.astype(int), 'counts': grouped_pd.counts}\n",
    "    grouped_pd2= pd.DataFrame(data=d)\n",
    "    result = pd.merge(grouped_pd2, atlas_labels, on=[\"id\"])\n",
    "    result.sort_values(['counts'], ascending=True, inplace=True)\n",
    "    # result is the final pd\n",
    "\n",
    "    return result\n",
    "\n",
    "def clean_duplicate(df):\n",
    "    '''\n",
    "    Used under the get_parent_excel function\n",
    "    This is needed again to account for parent regions that have its subregion incompletely covers the parent areas.\n",
    "    A painful example is Zona incerta, since it has a depth of 6, after group by parents it will show up twice with different counts where we simply just add the two counts\n",
    "    '''\n",
    "    \n",
    "    df2=df.groupby(['acronym'],as_index=False, sort=False).sum()\n",
    "    d= {'acronym': df2.acronym, 'counts': df2.counts}\n",
    "    grouped_pd2= pd.DataFrame(data=d)\n",
    "    result = pd.merge(grouped_pd2, atlas_labels, on=[\"acronym\"])\n",
    "    # this merging is required because pd.groupby will drop 'useless columns' such as depth, structure id path and other useful ones!! So we fetch them back here..\n",
    "    # Probably have better ways of doing it...\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_parent_excel(subregion_df):\n",
    "    ''' quantify axon counts in broader anatomical regions, where regions with depth>6 will be grouped one level up\n",
    "    this is done so that layers of cerebral cortex gets grouped together (ie, ssp-bfd l2/3,l4, l5 and l6 becomes ssp-bfd)\n",
    "    '''\n",
    "\n",
    "    axon_sub=subregion_df.sort_values(by=['counts'])\n",
    "    axon_sub.sort_values(by= 'graph_order',axis=0, inplace=True)\n",
    "\n",
    "    needsgroup=axon_sub[axon_sub.depth>6]\n",
    "    noneedsgroup=axon_sub[axon_sub.depth<=6]\n",
    "\n",
    "    parent= parent_df(needsgroup)\n",
    "\n",
    "    complete1=noneedsgroup.append(parent)\n",
    "\n",
    "    complete=clean_duplicate(complete1)\n",
    "\n",
    "    complete.sort_values('counts',ascending=False, inplace=True)\n",
    "    \n",
    "    return complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca48dff-4f9a-4e5c-a238-9e03757aecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='s2'\n",
    "# change to 's1' or 's2' and repeat\n",
    "\n",
    "indir = f'{working_directory}\\\\Horizontal_Axon\\\\{region}\\\\npy'\n",
    "#specifiy input folder containing the horizontal npy files\n",
    "\n",
    "in_files= os.listdir(indir)\n",
    "\n",
    "sample_files= os.listdir(indir)\n",
    "\n",
    "outdir =f'{working_directory}\\\\{region}_result'\n",
    "os.mkdir(outdir)\n",
    "# define folder to store the results\n",
    "\n",
    "atlas_labels=pd.read_csv(f'{working_directory}\\ARA_25_micron_mhd_ccf2017\\labels.csv')\n",
    "#read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65504a15-7303-4496-8380-ceabf5aafeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronal atlas has shape (528, 320, 456)\n",
      "Converted to horizontal atlas with shape (456, 528, 320)\n"
     ]
    }
   ],
   "source": [
    "mcc = MouseConnectivityCache(resolution=25)\n",
    "annot, annot_info = mcc.get_annotation_volume()\n",
    "print('Coronal atlas has shape', annot.shape)\n",
    "# load allen mouse brain atlas that is in coronal view\n",
    "\n",
    "annot_h=np.moveaxis(annot, 2, 0)\n",
    "print('Converted to horizontal atlas with shape', annot_h.shape)\n",
    "# reslice corontal atlas to horizontal atlas that is consistent with our sample's orientation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d287280-7fbe-47bd-a290-2fcf901a3733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [02:10<00:00,  6.89s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(sample_files):\n",
    "    \n",
    "    this_file= os.path.join(indir,i)\n",
    "    \n",
    "    mouse_name= find_mousename(this_file)\n",
    "    # identify mouse id\n",
    "\n",
    "    out_name= os.path.join(outdir,mouse_name)\n",
    "    #define a generic output file name for this sample\n",
    "\n",
    "    #print(f'now processing {mouse_name}')\n",
    "    \n",
    "    sample_h,this_axon= find_points_id_from_npy(this_file)\n",
    "    # read sample and axon indices\n",
    "\n",
    "    left_points= []\n",
    "    right_points= []\n",
    "    for item in this_axon:\n",
    "        if item[0]<227:\n",
    "            left_points.append(item)\n",
    "        else:\n",
    "            right_points.append(item)\n",
    "    # separate in to left and right hemisphere, defined by splitting the horizontal image down the middle\n",
    "\n",
    "    left_df= get_subregion_excel(left_points)\n",
    "    left_df.to_excel(out_name+'_left_region_with_counts.xlsx',index=None,header=True)\n",
    "\n",
    "    right_df= get_subregion_excel(right_points)\n",
    "    right_df.to_excel(out_name+'_right_region_with_counts.xlsx',index=None,header=True)\n",
    "\n",
    "\n",
    "    left_parent= get_parent_excel(left_df)\n",
    "    left_parent.to_excel(f'{out_name}_Lparent.xlsx') \n",
    "    #print('left_parent excel saved')\n",
    "\n",
    "    if len(right_points)==0:\n",
    "        right_df.to_excel(f'{out_name}_Rparent.xlsx') \n",
    "    else:\n",
    "        right_parent= get_parent_excel(right_df)\n",
    "        right_parent.to_excel(f'{out_name}_Rparent.xlsx') \n",
    "    #print('right_parent excel saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432c71d-760f-46a2-916f-dd35b0978d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis2",
   "language": "python",
   "name": "analysis2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
