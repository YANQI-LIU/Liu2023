{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd261459-ed4a-4f89-a06a-9cefc39f80e0",
   "metadata": {},
   "source": [
    "## Custom written code to generate Figure 3 and Figure 4 for Liu 2023\n",
    "\n",
    "Figure 3. sum projections of group averages\n",
    "\n",
    "Figure 4. serial coronal sections\n",
    "\n",
    "Also prepares intermediate files (xlsx) for the subsequent figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5016e031-4d58-4f02-8480-c957c068c3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Neuron_analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b427f03ca674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mNeuron_analysis\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mNeuron_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Neuron_analysis'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import warnings\n",
    "\n",
    "import tkinter.filedialog as fdialog\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import Neuron_analysis as na\n",
    "from Neuron_analysis import *\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271c05c3-1ef5-429a-ac3f-93f56ca21620",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Figure 3\n",
    "\n",
    "Sum projections of group averages in coronal, horizontal and saggital views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bf2ab-bf27-46a9-a796-705ea6200d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='s1'\n",
    "# or 's2'\n",
    "\n",
    "indir = f'D:\\\\viral_results\\\\{region}\\\\npy'\n",
    "#specifiy input folder containing the horizontal npy files\n",
    "\n",
    "outdir =f'D:\\\\viral_results\\\\{region}_average'\n",
    "# define folder to store the results\n",
    "\n",
    "in_files= os.listdir(indir)\n",
    "\n",
    "sample_files= os.listdir(indir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4da78-50eb-4f37-a2d1-6dd0750613ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tiff(numpystack, outname):\n",
    "    \n",
    "    '''save numpy stack as tiff and sum max projection in horizontal, coronal and saggital views'''\n",
    "    \n",
    "    print('Starting to saving tif files..')\n",
    "    \n",
    "    io.imsave(outname+'_axons.tif',numpystack,check_contrast=False)\n",
    "    \n",
    "    sum_0=np.sum(numpystack, axis=0)\n",
    "    sum_1=np.sum(numpystack, axis=1)\n",
    "    sum_2=np.sum(numpystack, axis=2)\n",
    "    io.imsave(outname+ '_sum_0.tif',sum_0,check_contrast=False)\n",
    "    io.imsave(outname+ '_sum_1.tif',sum_1,check_contrast=False)\n",
    "    io.imsave(outname+ '_sum_2.tif',sum_2,check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1300f98-c7ce-46da-8dbe-0c734f67776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY FOR SAMPLES!!\n",
    "\n",
    "if region == 's1':\n",
    "    sample_dictionary= {'sim': ['AL207','AL209','AL273'],\n",
    "                        'rbp': ['AL211','AL318'],\n",
    "                        'tlx': ['AL213','AL313','AL314'],\n",
    "                        'ras': ['AL254','AL255','AL257'],\n",
    "                        'scn': ['AL290','AL291','AL292','AL293'],\n",
    "                        'nts': ['AL274','AL285','AL311']\n",
    "                       }\n",
    "elif region == 's2':\n",
    "    sample_dictionary= {'sim': ['AL281','AL286','AL321','AL322'],\n",
    "                        'rbp': ['AL288','AL326','AL327'],\n",
    "                        'tlx': ['AL278','AL280','AL319'],\n",
    "                        'ras': ['AL303','AL332','AL333'],\n",
    "                        'scn': ['AL290','AL292','AL323'],\n",
    "                        'nts': ['AL274','AL310','AL330']\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c290c-ab60-4057-baf8-d6b23410415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genotype, sample_name in tqdm(sample_dictionary.items()):\n",
    "    \n",
    "    print ('Working on '+ genotype + ' samples') \n",
    "    \n",
    "    out_name= outdir+ f'\\\\{genotype}_average'\n",
    "    \n",
    "    relevant_npy_name= [i+'.npy' for i in sample_name]\n",
    "    # get the relevant names\n",
    "    \n",
    "    template=np.zeros([320, 528, 456])\n",
    "    # initialize np array\n",
    "    \n",
    "    for i in relevant_npy_name:\n",
    "        template+= np.load(os.path.join(indir,i))\n",
    "    \n",
    "    averaged_stack= template/ len(relevant_npy_name)\n",
    "    # average across number of involved samples\n",
    "    \n",
    "    np.save(out_name+'.npy', averaged_stack)\n",
    "    \n",
    "    averaged_stack[0,0,0]=0\n",
    "    averaged_stack[1,0,0]=0\n",
    "    # reassign these pixels back to 0\n",
    "    \n",
    "    save_tiff(averaged_stack, out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2d1d0-76b4-4d5a-991a-545acc275540",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Figure 4 WORK IN PROGRESS\n",
    "\n",
    "Serial coronal sections of group averages\n",
    "\n",
    "Sum projections of a few coronal sections centered around a given AP location\n",
    "- ie. 125 um thickness centered around AP +3 mm to -7 mm in 1 mm intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9571b-cae0-44b6-89c1-502cb23d1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir= r'D:\\viral_results\\consecutive_coronal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eab241f6-f160-4072-a1c6-3aad2d9daa25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'na' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-125aa2d74d0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# defined the list of transgenic lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbregma\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbregma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# bregma is section 215 in a coronal stack in the Allen brain 25um CCF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'na' is not defined"
     ]
    }
   ],
   "source": [
    "regions=['s1', 's2']\n",
    "# define the two injection regions\n",
    "\n",
    "mouse_lines=['ras','scn','tlx','sim','rbp','nts']\n",
    "# defined the list of transgenic lines\n",
    "\n",
    "bregma= na.bregma[2]\n",
    "# bregma is section 215 in a coronal stack in the Allen brain 25um CCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aab1553-0069-4411-b169-5f72b81e6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = -3\n",
    "# starting at 3 AP, note the negative sign\n",
    "\n",
    "end = 7\n",
    "# ending at -7 AP, note the positive sign\n",
    "\n",
    "thickness= 5\n",
    "pre= np.floor(thickness/2)\n",
    "post=np.floor(1+thickness/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c100c1f-f6ca-489f-aeb7-cb05fa0c10fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-663f3588f76b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmouse_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfile_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34mf'D:\\\\viral_results\\\\{i}_average\\\\{j}_average.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "# loop through group averages\n",
    "\n",
    "for i in regions:\n",
    "    \n",
    "    \n",
    "    for j in tqdm(mouse_lines):    \n",
    "        \n",
    "        file_path= f'D:\\\\viral_results\\\\{i}_average\\\\{j}_average.npy'\n",
    "\n",
    "        axons=np.load(file_path)\n",
    "        # load horizontal npy file of group averages\n",
    "        \n",
    "        axons[0,0,0]=0\n",
    "        axons[1,0,0]=0\n",
    "        # restore these values back to 0\n",
    "        \n",
    "        coronal= axons.swapaxes(0,1)\n",
    "        # reshape axons into coronal sections\n",
    "        \n",
    "        for k in range(start,end-1):\n",
    "            \n",
    "            #take -3 mm to  7 mm in 1 mm interval points with 5 sections (125 um) around this point, in terms of stereotaxic cordinate where bregma= 0\n",
    "            \n",
    "            midpoint= int( bregma + k/0.025)\n",
    "            # convert this stereotaxic point back where 1 pixel= 25 microns or 0.025 mm\n",
    "            \n",
    "            this_plane=coronal[midpoint-pre : midpoint+post,:,:].sum(0)\n",
    "            # keep 2 slices before and 2 slices after the midpoint, which is 5 slices in total= 125um thickness\n",
    "\n",
    "            out_name= f'{outdir}\\\\{i}_{j}_avg_AP{k}'\n",
    "\n",
    "            #io.imsave(out_name+ '_sum.tif',this_plane,check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58332b37-1f2e-4436-a059-7b4197c8e653",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-983e993bb1eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mregions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmouse_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "# cleaned up code above!\n",
    "\n",
    "# original code here\n",
    "\n",
    "\n",
    "outdir= r'D:\\viral_results\\consecutive_coronal'\n",
    "\n",
    "\n",
    "\n",
    "for i in regions:\n",
    "    for j in tqdm(mouse_lines):\n",
    "        \n",
    "        \n",
    "        file_path= f'D:\\\\viral_results\\\\{i}_average\\\\{j}_average.npy'\n",
    "\n",
    "        axons=np.load(file_path)\n",
    "        axons[0,0,0]=0\n",
    "        axons[1,0,0]=0\n",
    "        # restore these values back to 0\n",
    "        \n",
    "        coronal= axons.swapaxes(0,1)\n",
    "        # reshape axons into coronal sections\n",
    "        \n",
    "        for k in range(stereo_range):\n",
    "            #take -3 mm to 8 mm in 1 mm interval points with 5 sections (125 um) around this point, in terms of stereotaxic cordinate where bregma= 0\n",
    "            \n",
    "            midpoint= int( bregma + k/0.025)\n",
    "            # convert this stereotaxic point back\n",
    "            \n",
    "            this_plane=coronal[midpoint-2 : midpoint+3,:,:].sum(0)\n",
    "            # keep 2 slices before and 2 slices after the midpoint, which is 5 slices in total= 125um thickness\n",
    "\n",
    "            out_name= f'{outdir}\\\\{i}_{j}_avg_AP{k}'\n",
    "\n",
    "            io.imsave(out_name+ '_sum.tif',this_plane,check_contrast=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a4061-bcec-4e32-8b7f-c84548b4ea9c",
   "metadata": {},
   "source": [
    "### Preparation categorical data as excel files for Figures 5,6 and 7\n",
    "Numbers of of axons in brain region X\n",
    "\n",
    "Should get 4 xlsx files per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea25280d-e8c9-44ff-bf75-6689aa9e19bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# useful functions\n",
    "\n",
    "def find_points_id_from_npy(npy_file_path):\n",
    "    \n",
    "    ''' quantify amount of axons in brain region from npy files\n",
    "    '''\n",
    "    \n",
    "    sample_array=np.load(npy_file_path)\n",
    "    \n",
    "    sample_array[0,0,0]=0\n",
    "    sample_array[1,0,0]=0\n",
    "    # reassign position 0,0,0 and 1,0,0 as 0\n",
    "    # this is because we stored number of axons (at 0,0,0) and number of cells at(1,0,0) at these locations \n",
    "\n",
    "    sample_h=np.swapaxes(sample_array, 0, 2)\n",
    "    # swap axis to match the atlas shape, this is the axon in horizontal view\n",
    "    \n",
    "    axons= np.argwhere(sample_h)\n",
    "    # find all the non-zero indices from the stack\n",
    "    \n",
    "    return sample_h, axons\n",
    "\n",
    "def get_subregion_excel(axon_points):\n",
    "    \n",
    "    ''' Quantify axon counts in the most detailed anatomical region possible\n",
    "    '''\n",
    "    \n",
    "    region_in_atlas= []\n",
    "    for i in axon_points:\n",
    "        region_in_atlas.append(int(annot_h[i[0], i[1],i[2]]))\n",
    "    #get atlas id for each non-zero indices on this side side\n",
    "\n",
    "    axon_values=[]\n",
    "    for i in axon_points:\n",
    "        axon_values.append (sample_h[i[0],i[1],i[2]])\n",
    "    # get the actual count for each non-zero indices on this side\n",
    "\n",
    "    this_data=pd.DataFrame({'id': region_in_atlas, 'counts': axon_values})\n",
    "    # store in data frame\n",
    "\n",
    "    this_data=this_data.groupby(by='id').sum()\n",
    "    # add the values from a given brain region together\n",
    "    \n",
    "    this_df=pd.merge(atlas_labels, this_data, on='id')\n",
    "    # add in additional information from allen labels and save\n",
    "    \n",
    "    return this_df\n",
    "\n",
    "def parent_df(df):\n",
    "    ''' \n",
    "    Used under the get_parent_excel function\n",
    "    group dataframe by parent id structure'''\n",
    "    \n",
    "    grouped_pd=df.groupby(['parent_structure_id'],as_index=False).sum()\n",
    "    d= {'id': grouped_pd.parent_structure_id.astype(int), 'counts': grouped_pd.counts}\n",
    "    grouped_pd2= pd.DataFrame(data=d)\n",
    "    result = pd.merge(grouped_pd2, na.atlas_labels, on=[\"id\"])\n",
    "    result.sort_values(['counts'], ascending=True, inplace=True)\n",
    "    # result is the final pd\n",
    "\n",
    "    return result\n",
    "\n",
    "def clean_duplicate(df):\n",
    "    '''\n",
    "    Used under the get_parent_excel function\n",
    "    This is needed again to account for parent regions that have its subregion incompletely covers the parent areas.\n",
    "    A painful example is Zona incerta, since it has a depth of 6, after group by parents it will show up twice with different counts where we simply just add the two counts\n",
    "    '''\n",
    "    \n",
    "    df2=df.groupby(['acronym'],as_index=False, sort=False).sum()\n",
    "    d= {'acronym': df2.acronym, 'counts': df2.counts}\n",
    "    grouped_pd2= pd.DataFrame(data=d)\n",
    "    result = pd.merge(grouped_pd2, na.atlas_labels, on=[\"acronym\"])\n",
    "    # this merging is required because pd.groupby will drop 'useless columns' such as depth, structure id path and other useful ones!! So we fetch them back here..\n",
    "    # Probably have better ways of doing it...\n",
    "    \n",
    "    return result\n",
    "def get_parent_excel(subregion_df):\n",
    "    ''' quantify axon counts in broader anatomical regions, where regions with depth>6 will be grouped one level up\n",
    "    this is done so that layers of cerebral cortex gets grouped together (ie, ssp-bfd l2/3,l4, l5 and l6 becomes ssp-bfd)\n",
    "    '''\n",
    "\n",
    "    axon_sub=subregion_df.sort_values(by=['counts'])\n",
    "    axon_sub.sort_values(by= 'graph_order',axis=0, inplace=True)\n",
    "\n",
    "    needsgroup=axon_sub[axon_sub.depth>6]\n",
    "    noneedsgroup=axon_sub[axon_sub.depth<=6]\n",
    "\n",
    "    parent= parent_df(needsgroup)\n",
    "\n",
    "    complete1=noneedsgroup.append(parent)\n",
    "\n",
    "    complete=clean_duplicate(complete1)\n",
    "\n",
    "    complete.sort_values('counts',ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ca48dff-4f9a-4e5c-a238-9e03757aecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='s1'\n",
    "# or 's2'\n",
    "\n",
    "indir = f'D:\\\\viral_results\\\\{region}\\\\npy'\n",
    "#specifiy input folder containing the horizontal npy files\n",
    "\n",
    "\n",
    "in_files= os.listdir(indir)\n",
    "\n",
    "sample_files= os.listdir(indir)\n",
    "\n",
    "outdir =f'D:\\\\viral_results\\\\{region}_result'\n",
    "# define folder to store the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65504a15-7303-4496-8380-ceabf5aafeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache(resolution=25)\n",
    "annot, annot_info = mcc.get_annotation_volume()\n",
    "print('Coronal atlas has shape', annot.shape)\n",
    "# load allen mouse brain atlas that is in coronal view\n",
    "\n",
    "annot_h=np.moveaxis(annot, 2, 0)\n",
    "print('Converted to horizontal atlas with shape', annot_h.shape)\n",
    "# reslice corontal atlas to horizontal atlas that is consistent with our sample's orientation\n",
    "\n",
    "atlas_labels=pd.read_csv('D:\\Allenbrainatlas\\ARA_25_micron_mhd_ccf2017\\labels.csv')\n",
    "# read axon labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d287280-7fbe-47bd-a290-2fcf901a3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(sample_files):\n",
    "    \n",
    "    this_file= os.path.join(indir,i)\n",
    "    \n",
    "    mouse_name= na.find_mousename(this_file)\n",
    "    # identify mouse id\n",
    "\n",
    "    out_name= os.path.join(outdir,mouse_name)\n",
    "    #define a generic output file name for this sample\n",
    "\n",
    "    #print(f'now processing {mouse_name}')\n",
    "    \n",
    "    sample_h,this_axon= find_points_id_from_npy(this_file)\n",
    "    # read sample and axon indices\n",
    "\n",
    "    left_points= []\n",
    "    right_points= []\n",
    "    for item in this_axon:\n",
    "        if item[0]<227:\n",
    "            left_points.append(item)\n",
    "        else:\n",
    "            right_points.append(item)\n",
    "    # separate in to left and right hemisphere, defined by splitting the horizontal image down the middle\n",
    "\n",
    "    left_df= get_subregion_excel(left_points)\n",
    "    left_df.to_excel(out_name+'_left_region_with_counts.xlsx',index=None,header=True)\n",
    "\n",
    "    right_df= get_subregion_excel(right_points)\n",
    "    right_df.to_excel(out_name+'_right_region_with_counts.xlsx',index=None,header=True)\n",
    "\n",
    "\n",
    "    left_parent= get_parent_excel(left_df)\n",
    "    left_parent.to_excel(f'{out_name}_Lparent.xlsx') \n",
    "    #print('left_parent excel saved')\n",
    "\n",
    "    if len(right_points)==0:\n",
    "        right_df.to_excel(f'{out_name}_Rparent.xlsx') \n",
    "    else:\n",
    "        right_parent= get_parent_excel(right_df)\n",
    "        right_parent.to_excel(f'{out_name}_Rparent.xlsx') \n",
    "    #print('right_parent excel saved')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis2",
   "language": "python",
   "name": "analysis2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
